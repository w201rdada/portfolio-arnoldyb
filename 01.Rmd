# Winning Over Public Opinion By Measuring Minds Changed {#persuasion-metrics}
#### Keywords

persuasion, sentiment analysis, personality profiles, natural language processing, social media
<!-- BA: one thing I should think about is whether this course has been one long refutation of the very idea of persuasion, particularly those who are not fence-sitters or are somehow persuadable. What persuasion does seem to exist has been presented as manipulation or gaming the cognitive system of people. Also: very interesting concepts from Asynch 11... the notion that you extend an invitation, not an ask.-->
## Going beyond viewership
<!-- Fine, but read the headings by themselves. Do they also provide a synopsis? // BA: redo these at the end -->
Imagine you make a video to convince Americans that climate change is real and the video goes viral. Let's say 10 million people view it. Were you successful? It's impossible to answer that question without knowing how many of the viewers were climate skeptics before watching and accepted climate change after watching. This problem is writ large across organizations tasked with changing public opinion. Unlike online retailers with digital shopping carts, organizations that are selling ideas don't have a "buy" button to monitor. Consequently, these organizations -- including foundations, think tanks, political parties, and special interest groups -- are spending big money on content that they only vaguely know to be effective.
<!-- BA: should I simply whittle this down to one specific organization doing this, say Earthjustice, so I don't keep getting the frustrating comment that people aren't sure who would use this, despite iterating this list of types of organizations?-->
<!-- Pure numbers can be justified with some heavy assumptions. Indeed big numbers become even more important the weaker the effect. // BA: I think Brooks' basic take is that "weak indicator" data is good enough at scale, and "strong indicator" data of focus groups and polls are statistically valid to extend across big populations, so that this problem is already solved in two different ways. What this misses: The "weak indicator" data are very hard for non-technical orgs to know how to interpret, and the "strong indicator" data are too inexpensive and slow for daily decisionmaking by content-makers.-->
<!-- What kinds of buttons do they already have, or already use? // BA: there are various raw markers of engagement that are require more data to really understand what's meant by each user. But the raw markers are "likes" and other positive signs of engagement on social, site-specific reaction buttons ("Was this content helpful?"), Disqus comments, email to friend.  -->
<!-- BA: should I draw up a research question to end this section? -->
## Using sentiment analysis 
<!-- This section is about more than sentiment analysis. Indeed you'll want more than one method. // BA: change up header; other concepts are personality profiling, statistical experiments -->
Current solutions to the problem include focus groups and polling. Focus groups can measure the effectiveness of specific messaging phrases on a very small group in a highly artificial setting. Polling captures self-reported shifts in broad public opinion, but can't easily pinpoint that to any given content.
<!-- Polling could implement a pre-post within person design. // BA: Good point, so I think I need to amend this to highlight the slowness and extreme cost of this solution, as well as the bias of how people report to pollsters rather than observed response. -->
Cambridge Analytica, the firm hired by the Brexit and Trump campaigns, showed the potential of using big data to shift opinion through better audience targeting. Evidence suggests they used the data captured from Facebook likes to build personality [profiles of the entire U.S. population](/https://motherboard.vice.com/en_us/article/mg9vvn/how-our-likes-helped-trump-win), then delivered individuals specific online content to influence their opinions of Trump and Clinton. However, it's not clear they used anything innovative in determining which messages worked best -- instead, they could draw on the massive infrastructure of a national campaign with volunteers to check in on voters and get a rough sense of what worked. 

I see a tremendous opportunity to go further with data science to actually measure the persuasiveness of content. <!-- Subtle shift in unit of analysis. // BA: different than Measuring # of minds changed I guess. Okay. I prefer to talk about minds changed rather than scoring content. --> Populations can be split into opinion groups using [sentiment analysis](/https://en.wikipedia.org/wiki/Sentiment_analysis) of their social media posts on the topic. A certain group can be pushed persuasive content and monitored for changes in sentiment in their reaction and in any subsequent social media posts on the topic. In this way, opinion marketers can start to build conversion rate metrics on content, and piece together more sophisticated [remarketing campaigns](/http://rejoiner.com/resources/remarketing-vs-retargeting-whats-the-difference/).
<!-- How is social media policy changing to help or hinder such efforts? // BA: This was always tricky with Facebook. CambAn may have built personality profiles using online tests that users would voluntary open their account to scraping. Twitter has always seemed like anything goes as long as you don't try to scrape the entirety but play within their throttling. But I don't think he's asking about this level of detail, more the moral shift in silicon valley post election 2016. Also, the backlash from the Facebook emotions experiment. We'd have to avoid following pitfalls: targeting those holding hateful beliefs, offering false information to persuade, lack of transparency of who provides the messaging, and the lack of consent around the expriment. Probably should have a graf just on how to do this ethically, though there's some doubt in my mind if every one of those ethical boxes could be checked. -->
## A future with better arguments
<!-- better manipulation? consider unintended consequences // BA: he didn't seem to buy the better arguments frame. what is the difference between persuasion and manipulation to me? transparency/consent. the one being persuaded knows who is the persuader, knows that the persuader is trying to persuade. and accuracy. that the persuasion is being done with truthful information. -->
This initial solution to the problem of measuring what changes minds faces some serious limitations. Initial measurements may reveal that it is very rare for anyone's mind to change based on one piece of content, or that such shifts don't last very long without continuous messaging. And "change of mind" is rarely a binary event (a sudden flip from disagree to agree), but a slow shift along a continuum of opinion that may be harder to measure. But we won't know these shortfalls until taking this first step toward measuring persuasion. 
<!-- You're taking a tacitly cynical stance on democratic ethics. // BA: I guess he's saying that because I haven't addressed ethics to this point. I think this entire section will need to be an exploration of how one could do this ethically. -->
The solution would likely face ethical concerns around the tracking of individuals' opinions, though less so if the information is used purely to persuade rather than to exclude or penalize. 

Any metrics tools that get developed around persuasion would eventually spread to both sides of any given issue, so ultimately the data wouldn't result in any longlasting advantages to the first-movers. Instead, the metrics should help issue advocates argue better by clarifying misunderstandings and illuminating areas of real disagreement that need negotiation. The data could also save money for issue advocates who could determine that persuasion campaigns do not have the results to justify the expenditure. 
<!-- How to avoid a race to the bottom? -->
<!-- Brooks' final comment: I'm most fascinated by the moral ambivalence of this proposal. I probably enjoy it more for that reason, but I think clarifying your moral position will also help you develop more concrete tactics about what should be done. Attempting moral neutrality (albeit the dubious neutrality of an arms dealer) is one option, and currently the default. I would welcome some basic internal dialogue, for instance, about how ends justify means.-->
